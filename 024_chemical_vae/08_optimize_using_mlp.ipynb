{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "AXzK4RspR1P3"
   },
   "execution_count": 139,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode_smiles(smiles, charset, max_length=120):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(charset))\n",
    "    integer_encoded = [char_to_int[char] for char in smiles]\n",
    "    if len(integer_encoded) > max_length:\n",
    "        integer_encoded = integer_encoded[:max_length]\n",
    "    else:\n",
    "        integer_encoded = integer_encoded + [0] * (max_length - len(integer_encoded))\n",
    "    onehot_encoded = np.zeros((max_length, len(charset)), dtype=np.float32)\n",
    "    for i, val in enumerate(integer_encoded):\n",
    "        onehot_encoded[i, val] = 1.0\n",
    "\n",
    "    return onehot_encoded"
   ],
   "metadata": {
    "id": "5fkNBUBGR2fA"
   },
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def decode_smiles_from_one_hot(one_hot_encoded, charset):\n",
    "    int_to_char = {i: c for i, c in enumerate(charset)}\n",
    "    integer_decoded = np.argmax(one_hot_encoded, axis=1)\n",
    "    chars = [int_to_char[idx] for idx in integer_decoded]\n",
    "    smiles = \"\".join(chars).rstrip()\n",
    "\n",
    "    return smiles"
   ],
   "metadata": {
    "id": "Lg74OjhvR6AP"
   },
   "execution_count": 141,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class MolecularVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularVAE, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(120, 9, kernel_size=9)\n",
    "        self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n",
    "        self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n",
    "        self.linear_0 = nn.Linear(90, 435)\n",
    "        self.linear_1 = nn.Linear(435, 292)\n",
    "        self.linear_2 = nn.Linear(435, 292)\n",
    "\n",
    "        self.linear_3 = nn.Linear(292, 292)\n",
    "        self.gru = nn.GRU(292, 501, 3, batch_first=True)\n",
    "        self.linear_4 = nn.Linear(501, 35)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.relu(self.conv_1(x))\n",
    "        x = self.relu(self.conv_2(x))\n",
    "        x = self.relu(self.conv_3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.selu(self.linear_0(x))\n",
    "        return self.linear_1(x), self.linear_2(x)\n",
    "\n",
    "    def sampling(self, z_mean, z_logvar):\n",
    "        epsilon = 1e-2 * torch.randn_like(z_logvar)\n",
    "        return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = F.selu(self.linear_3(z))\n",
    "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, 120, 1)\n",
    "        output, hn = self.gru(z)\n",
    "        out_reshape = output.contiguous().view(-1, output.size(-1))\n",
    "        y0 = F.softmax(self.linear_4(out_reshape), dim=1)\n",
    "        y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_logvar = self.encode(x)\n",
    "        z = self.sampling(z_mean, z_logvar)\n",
    "        return self.decode(z), z_mean, z_logvar"
   ],
   "metadata": {
    "id": "uY9fFOGqU8C5"
   },
   "execution_count": 142,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vae_model = MolecularVAE()\n",
    "checkpoint = torch.load(\"/content/drive/MyDrive/checkpoints/checkpoint_epoch_60.pt\")\n",
    "vae_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "vae_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae_model = vae_model.to(device)\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdFUVQbNU_Au",
    "outputId": "fc9f5351-a5ed-487c-8988-b5fca9748908"
   },
   "execution_count": 143,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "fHN2Fsu7Vnsg"
   },
   "outputs": [],
   "source": [
    "class SMILESLogPDataset(Dataset):\n",
    "    def __init__(self, smiles_list, charset, logp_list, vae_model):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.charset = charset\n",
    "        self.logp_list = logp_list\n",
    "        self.vae_model = vae_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.smiles_list[idx]\n",
    "        encoded_smiles = one_hot_encode_smiles(smiles, self.charset)\n",
    "        logp = self.logp_list[idx]\n",
    "        return torch.FloatTensor(encoded_smiles), smiles, logp"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "df[\"smiles\"] = df[\"smiles\"].str.rstrip(\"\\n\")\n",
    "\n",
    "charset = set(\"\".join(df[\"smiles\"].values.tolist()))\n",
    "charset = sorted(list(charset))\n",
    "charset.insert(0, \" \")"
   ],
   "metadata": {
    "id": "YQI21w4xR_Jf"
   },
   "execution_count": 145,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = SMILESLogPDataset(\n",
    "    df[\"smiles\"].values.tolist(), charset, df[\"logP\"].values.tolist(), vae_model\n",
    ")"
   ],
   "metadata": {
    "id": "yBF4ixTyVwa5"
   },
   "execution_count": 146,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_ratio = 0.2\n",
    "\n",
    "test_size = int(test_ratio * len(dataset))\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ],
   "metadata": {
    "id": "gO1tWEHXSkJ2"
   },
   "execution_count": 147,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128)\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCm73nTUTO9i",
    "outputId": "11f44326-322a-4601-d156-64e0daf30eb5"
   },
   "execution_count": 148,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x793253316750>"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pxnyo5kkWXO",
    "outputId": "520142f3-7e68-4d5f-9dbe-6ad3c2ec1a54"
   },
   "execution_count": 149,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "199564"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(256)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.batch_norm1(self.fc1(x))))\n",
    "        x = self.dropout(self.relu(self.batch_norm2(self.fc2(x))))\n",
    "        x = self.dropout(self.relu(self.batch_norm3(self.fc3(x))))\n",
    "        x = self.dropout(self.relu(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "i-nHPXSBXN1L"
   },
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "input_dim = 292\n",
    "model = MLPRegressor(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 500\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for ohe, _, logp in train_loader:\n",
    "        ohe = ohe.to(device).float()\n",
    "        logp = logp.to(device).float().view(-1, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z_mean, z_logvar = vae_model.encode(ohe)\n",
    "            z = vae_model.sampling(z_mean, z_logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(z)\n",
    "        loss = criterion(outputs, logp)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for ohe, _, logp in test_loader:\n",
    "            ohe = ohe.to(device).float()\n",
    "            logp = logp.to(device).float().view(-1, 1)\n",
    "\n",
    "            z_mean, z_logvar = vae_model.encode(ohe)\n",
    "            z = vae_model.sampling(z_mean, z_logvar)\n",
    "\n",
    "            outputs = model(z)\n",
    "            loss = criterion(outputs, logp)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Average test loss: {avg_test_loss:.4f}\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_loss\": total_loss,\n",
    "        },\n",
    "        f\"/content/drive/MyDrive/checkpoints/mlp_logp_regressor_epoch_{epoch}.pt\",\n",
    "    )\n",
    "    print(\"Training completed and model saved.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "y_S_5ECiXUoL",
    "outputId": "c428b800-61e1-4099-fd11-41720f807587"
   },
   "execution_count": 151,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-de09be187719>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mper_device_and_dtype_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zero_grad_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         self.record = torch.ops.profiler._record_function_enter_new(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_dim = 292\n",
    "model = MLPRegressor(input_dim)\n",
    "checkpoint = torch.load(\n",
    "    \"/content/drive/MyDrive/checkpoints/mlp_logp_regressor_epoch_499.pt\"\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojALx2CjWNmy",
    "outputId": "c0ce874d-ae2d-4e0e-e19a-dfe111d6beac"
   },
   "execution_count": 152,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPRegressor(\n",
       "  (fc1): Linear(in_features=292, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc5): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from logging import log\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "num_iterations = 1000\n",
    "\n",
    "model.eval()\n",
    "z = torch.randn(1, input_dim, requires_grad=True)\n",
    "z_history = torch.empty((num_iterations // 100 + 1, 1, input_dim))\n",
    "logp_history = []\n",
    "optimizer = optim.Adam([z], lr=lr)\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predicted_logP = model(z)\n",
    "    loss = predicted_logP\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Iteration {i+1}, Predicted LogP: {predicted_logP.item():.4f}\")\n",
    "        logp_history.append(predicted_logP.item())\n",
    "        z_history[i // 100] = z.detach().clone()\n",
    "\n",
    "z_opt = z.detach()\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_logP = model(z_opt)\n",
    "print(f\"Final optimized LogP: {final_logP.item():.4f}\")\n",
    "print(\"Optimized input vector:\")\n",
    "print(z_opt)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpOHHcrYRSaK",
    "outputId": "f5c28314-38a5-4842-891d-cd070a96c201"
   },
   "execution_count": 153,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 100, Predicted LogP: 1.8741\n",
      "Iteration 200, Predicted LogP: -1.1236\n",
      "Iteration 300, Predicted LogP: -2.4987\n",
      "Iteration 400, Predicted LogP: -3.7894\n",
      "Iteration 500, Predicted LogP: -5.3355\n",
      "Iteration 600, Predicted LogP: -8.9677\n",
      "Iteration 700, Predicted LogP: -22.2083\n",
      "Iteration 800, Predicted LogP: -41.4113\n",
      "Iteration 900, Predicted LogP: -58.4973\n",
      "Iteration 1000, Predicted LogP: -71.5192\n",
      "Final optimized LogP: -71.6371\n",
      "Optimized input vector:\n",
      "tensor([[ 4.4355e-01, -4.3069e-01,  7.0372e-01,  1.1605e+00, -1.3759e+00,\n",
      "          2.9366e+00, -1.5973e+00,  5.9685e-01, -4.9110e-01, -1.7654e-01,\n",
      "          1.2772e+00, -1.9186e+00,  1.4255e-01,  1.2807e+00,  9.7490e-01,\n",
      "          2.4773e+00,  1.4204e+00, -2.3928e-03, -5.6430e-02, -1.2289e-02,\n",
      "         -3.0847e-01,  1.3775e+00, -4.1097e-01,  7.7727e-02,  2.9289e-01,\n",
      "         -1.6312e+00,  4.5520e-01, -8.6815e-02, -1.6836e-01,  2.7462e+00,\n",
      "         -1.3220e+00,  4.4604e-01, -2.0065e+00, -4.5698e-01,  6.6975e-01,\n",
      "          5.0952e-01,  6.4281e-01, -3.9281e-01,  2.8220e-01, -1.2997e-01,\n",
      "         -1.0423e-01, -5.1527e-01, -2.0172e+00, -1.4502e+00,  4.9275e-01,\n",
      "          1.0035e+00, -1.2077e+00, -1.4062e-02,  1.9784e-01,  2.2248e-01,\n",
      "         -3.6920e-01,  5.3390e-01,  2.1160e+00,  2.6004e+00,  4.4959e-01,\n",
      "         -5.0740e-01,  1.0731e+00,  2.9381e+00,  2.4333e+00, -1.7013e+00,\n",
      "          5.7023e-01,  4.7942e-01,  9.1106e-01, -2.1883e-01, -1.1955e-01,\n",
      "          1.3020e+00,  3.4798e-01, -1.5658e+00, -1.5615e+00,  2.9527e+00,\n",
      "         -1.9768e+00,  1.1550e+00,  7.8340e-01, -2.1247e+00,  9.7471e-01,\n",
      "          6.8784e-01,  1.6620e-01, -1.3782e-01,  1.4201e+00, -7.7788e-01,\n",
      "          2.1448e-01,  2.6050e-01, -2.7071e+00,  8.8729e-01, -1.9491e+00,\n",
      "         -1.3178e+00, -1.4980e+00,  2.1838e+00, -7.6413e-01,  1.0431e-01,\n",
      "          9.4430e-01,  2.0284e-01,  1.5317e+00,  8.5445e-01, -1.2893e+00,\n",
      "         -1.3973e-01, -1.0547e+00, -2.0168e+00,  5.7696e-01, -3.3794e-01,\n",
      "          1.4239e-01,  2.9734e-01, -4.5306e-01,  2.0522e+00, -1.4603e+00,\n",
      "         -6.8295e-01, -8.2589e-02,  7.0185e-01, -2.2365e-01,  1.0612e+00,\n",
      "          1.6524e+00,  1.7616e+00,  5.0868e-01, -3.2414e-02, -4.6717e-01,\n",
      "          3.6015e-01, -3.3324e-01, -1.7304e-01,  2.2070e+00, -4.0793e-01,\n",
      "          8.7505e-01,  3.2426e-01, -1.1820e+00, -1.6920e+00, -9.2372e-01,\n",
      "          4.7311e-01,  7.7366e-01,  2.8647e+00,  1.5170e+00, -1.6784e+00,\n",
      "          1.8239e+00, -1.8384e+00,  7.2426e-01,  1.4649e-01, -1.2008e+00,\n",
      "          7.1199e-01, -1.1438e+00, -1.5043e+00,  8.3205e-01,  5.1143e-01,\n",
      "          3.3933e-02, -5.8014e-01,  1.0550e+00, -4.5530e-01,  2.6762e-01,\n",
      "         -2.0700e+00,  1.8757e+00,  9.1519e-01,  2.2716e-01,  8.7249e-01,\n",
      "          2.2514e-01, -2.2218e-01, -3.3450e+00, -2.3136e-01,  1.2975e+00,\n",
      "         -1.1402e-01, -2.5109e-01, -2.3008e+00,  1.5418e+00,  7.8446e-01,\n",
      "          1.4516e+00,  1.0773e+00, -1.4985e+00, -7.1108e-01,  2.7963e+00,\n",
      "         -2.1089e+00,  3.7876e-01, -8.6301e-01,  7.8166e-01,  2.8315e+00,\n",
      "         -2.4185e+00, -5.1425e-02,  1.2446e+00, -1.1950e+00, -1.4258e-01,\n",
      "          1.3521e+00,  1.0236e+00,  7.2653e-02, -8.7515e-01, -9.8223e-01,\n",
      "         -1.5472e-01, -2.1285e+00, -1.1373e+00, -1.4036e+00,  9.2961e-01,\n",
      "         -8.1207e-03,  6.8592e-01, -1.2657e+00, -2.2958e-01, -1.3664e+00,\n",
      "         -1.7250e-01,  3.6911e-01,  1.4242e+00,  5.9428e-01, -1.3051e+00,\n",
      "          1.3498e+00,  1.8110e+00,  7.0042e-01,  1.3692e+00, -1.1715e+00,\n",
      "         -6.0224e-01,  9.8203e-01,  1.0212e+00,  1.1547e+00, -2.5002e+00,\n",
      "          8.1874e-01, -1.6984e+00,  6.3664e-03, -2.2514e-01, -5.3505e-01,\n",
      "         -2.3921e-01,  1.1644e+00,  1.6474e-01, -3.3547e-02, -1.5062e-01,\n",
      "          2.1693e-01,  4.5761e-02,  9.4258e-01, -5.3310e-01, -7.0782e-01,\n",
      "         -8.9140e-01, -5.5949e-01,  2.3149e-01, -1.6998e+00,  2.6126e+00,\n",
      "          7.0480e-01, -1.2538e+00, -1.1683e+00,  1.4947e-01, -8.3747e-01,\n",
      "         -8.9490e-01, -1.0431e+00,  4.0050e-01, -5.6243e-01,  1.5211e+00,\n",
      "          1.1432e+00, -2.9057e+00,  8.3408e-02,  2.4918e+00,  2.6018e+00,\n",
      "          1.1205e-01, -1.3216e-01,  6.6184e-01, -5.6373e-01,  2.4299e+00,\n",
      "          1.9867e+00,  4.2818e-01, -3.7026e-01,  1.4204e+00, -1.0124e+00,\n",
      "         -1.9148e+00, -1.2066e+00,  1.6464e+00,  1.9277e+00, -1.5881e+00,\n",
      "          3.8829e-01, -1.8593e+00,  7.3255e-01, -2.2588e+00,  1.0432e+00,\n",
      "          4.8936e-01, -6.0545e-01,  1.6258e+00,  1.3337e+00, -1.2701e+00,\n",
      "         -2.2283e+00,  1.4457e-01, -1.1284e+00, -1.9245e-01, -4.6364e-01,\n",
      "         -1.8301e-01,  4.5626e-02, -7.4270e-01,  2.9692e-01, -8.2376e-01,\n",
      "          8.5977e-01, -6.9110e-01,  6.7935e-01, -1.6223e+00,  6.2305e-01,\n",
      "          3.9359e-01,  3.6160e-01, -2.3405e-01,  1.9565e+00, -4.9745e-01,\n",
      "         -6.1889e-01,  1.3097e+00, -9.1222e-02,  2.0644e+00,  1.9360e+00,\n",
      "          1.6439e+00, -1.3670e+00]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "z_opt = z_opt.cpu()\n",
    "vae_model = vae_model.cpu()\n",
    "ohe_opt = vae_model.decode(z_opt)"
   ],
   "metadata": {
    "id": "3UpskksYSanR"
   },
   "execution_count": 154,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ohe_opt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvSTogQmSlTp",
    "outputId": "4e7e599c-61a1-4913-f2f9-47ef4bb1ccfc"
   },
   "execution_count": 155,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[6.2733e-04, 5.4162e-03, 1.0074e-04,  ..., 6.6311e-05,\n",
       "          1.6166e-03, 7.7639e-05],\n",
       "         [1.8233e-05, 3.4739e-04, 1.1427e-03,  ..., 3.2508e-09,\n",
       "          4.3327e-06, 3.4078e-08],\n",
       "         [7.0299e-07, 1.0436e-05, 1.2286e-04,  ..., 9.1528e-11,\n",
       "          1.7173e-06, 1.0077e-10],\n",
       "         ...,\n",
       "         [7.6942e-07, 5.0528e-06, 2.2785e-04,  ..., 6.6574e-09,\n",
       "          7.5214e-07, 3.3726e-09],\n",
       "         [2.0884e-06, 1.1549e-06, 5.7578e-03,  ..., 4.7579e-09,\n",
       "          5.8374e-07, 4.6483e-09],\n",
       "         [1.2700e-06, 2.1563e-06, 8.8738e-03,  ..., 1.6911e-09,\n",
       "          2.3550e-07, 1.4530e-09]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "generated_smiles = [\n",
    "    decode_smiles_from_one_hot(ohe.detach().cpu().numpy(), charset) for ohe in ohe_opt\n",
    "]"
   ],
   "metadata": {
    "id": "XumC4NbqS-UG"
   },
   "execution_count": 156,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generated_smiles"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaN6itO-TDmw",
    "outputId": "1ce0fe62-f388-420b-8038-f55764205f37"
   },
   "execution_count": 157,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['C/PP[P[PP[[[PPPPPPPPP[[PPPP[[[PPPP[[PPPP[[PPP][[PPP][[PPP][[PPPP[[PPPP[[PPPP[[PPPP[[PPPP][PPPP][[PPP][[PPPP[[PPPP[[PPPP[']"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vae_model = vae_model.cpu()\n",
    "ohe_history = vae_model.decode(z_history.cpu())"
   ],
   "metadata": {
    "id": "vFxXEl_hTU5o"
   },
   "execution_count": 158,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generated_smiles = [\n",
    "    decode_smiles_from_one_hot(ohe.detach().cpu().numpy(), charset)\n",
    "    for ohe in ohe_history\n",
    "]"
   ],
   "metadata": {
    "id": "u0NwO-jqTrZK"
   },
   "execution_count": 159,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generated_smiles"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B57Ck5ykUjzM",
    "outputId": "ad58a079-4e9f-441d-d492-16312bebfe15"
   },
   "execution_count": 160,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['CCCCCC@](CCCCCCCCCCCCCCCC1[CC@]([[[[)[[)[[@@[[C@@H[[[#@@()####-#',\n",
       " 'CCCCCC@](CCCCCCCCCCCCC@@1[C@@]([N)[([C@]([))[[[C@[[@@@@)##C)C',\n",
       " 'CCCCP@]]NCCCCCCCCCCCCCC@1[[C@]([[N+][[N@[([C@[([C@@@[C@@]()C',\n",
       " 'CCCP@@](NCCCCCCCCCCCCCCC1[[@H]([NH+][[@@]([O)[[[C@[[[C@@H((CCC',\n",
       " 'CCPP@H](CCCCCCCCCCCCCCCCCC[[[[NH]([C@H][[NH+][[[H[[[[@[][C@HH]]',\n",
       " 'C//CC@]/NCCCCCCCCCCCCC@]([C@H]([C@H][CC@]([C@H]([C@H](CC@H]CCC@H]CCC@H][CC@]([C@H]([C@H](CC@H][CC@]][C@H]([C@H](CC@H][CC',\n",
       " 'C/[C@@@](CC@@H[[N@@H[[N@HH[[N@@H[[N@@H[[N@@H[[N@@H[[N@@H[[N@@H[[N@HH[[N@HH[[N@H][[N@H][[N@H][[N@H][[NHH][[NHH][[NHH][[NH',\n",
       " 'CN[[@@@][[[@@H[[[@HH[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[',\n",
       " 'C/P[[P[[[[[[PP[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[',\n",
       " 'C/PP[P[PP[[[PPPPPPPPP[[PPPP[[[PPPP[[PPPP[[PPP][[PPP][[PPP][[PPPP[[PPPP[[PPPP[[PPPP[[PPPP][PPPP][[PPP][[PPPP[[PPPP[[PPPP[',\n",
       " '56666666O6655555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555(CCCCC']"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ohe, _, logP = dataset[0]\n",
    "ohe = ohe.unsqueeze(0)\n",
    "ohe = ohe.to(device)\n",
    "vae_model.to(device)\n",
    "with torch.no_grad():\n",
    "    z_mean, z_logvar = vae_model.encode(ohe)\n",
    "    z = vae_model.sampling(z_mean, z_logvar)\n",
    "z.requires_grad = True"
   ],
   "metadata": {
    "id": "b5NKRuX8WKVd"
   },
   "execution_count": 161,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ohe_opt = vae_model.decode(z)\n",
    "init_smiles = [\n",
    "    decode_smiles_from_one_hot(ohe.detach().cpu().numpy(), charset) for ohe in ohe_opt\n",
    "]\n",
    "init_smiles, logP"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uyjJDmHX93H",
    "outputId": "956aad2a-e7a9-47ca-9fee-99f097cc6722"
   },
   "execution_count": 162,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['CC(C)(C)c1ccc2ccc(CC(=O)Nc3ccccc3F)ccc1'], 5.0506)"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from logging import log\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "num_iterations = 1000\n",
    "model.eval()\n",
    "z_history = torch.empty((num_iterations // 100 + 1, 1, input_dim))\n",
    "logp_history = []\n",
    "optimizer = optim.Adam([z], lr=lr)\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    model.to(device)\n",
    "    predicted_logP = model(z)\n",
    "    loss = predicted_logP.sum()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\n",
    "            f\"Iteration {i+1}, Loss: {loss}, Predicted LogP: {predicted_logP.item():.4f}\"\n",
    "        )\n",
    "        logp_history.append(predicted_logP.item())\n",
    "        z_history[i // 100] = z.detach().clone()\n",
    "\n",
    "z_opt = z.detach()\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_logP = model(z_opt)\n",
    "print(f\"Final optimized LogP: {final_logP.item():.4f}\")\n",
    "print(\"Optimized input vector:\")\n",
    "print(z_opt)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ2FX9uTUyym",
    "outputId": "343b8362-6491-4765-e15d-81e513e94762"
   },
   "execution_count": 163,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 100, Loss: -0.010578632354736328, Predicted LogP: -0.0106\n",
      "Iteration 200, Loss: -0.8642542362213135, Predicted LogP: -0.8643\n",
      "Iteration 300, Loss: -1.1348967552185059, Predicted LogP: -1.1349\n",
      "Iteration 400, Loss: -7.113698959350586, Predicted LogP: -7.1137\n",
      "Iteration 500, Loss: -17.729915618896484, Predicted LogP: -17.7299\n",
      "Iteration 600, Loss: -28.3962459564209, Predicted LogP: -28.3962\n",
      "Iteration 700, Loss: -38.10822677612305, Predicted LogP: -38.1082\n",
      "Iteration 800, Loss: -47.125694274902344, Predicted LogP: -47.1257\n",
      "Iteration 900, Loss: -55.94256591796875, Predicted LogP: -55.9426\n",
      "Iteration 1000, Loss: -66.79432678222656, Predicted LogP: -66.7943\n",
      "Final optimized LogP: -66.9037\n",
      "Optimized input vector:\n",
      "tensor([[ 6.5844e-02,  7.8179e-01, -1.7205e-01, -3.4570e-01,  6.6610e-01,\n",
      "         -5.8852e-01, -7.7552e-01,  9.3110e-01, -9.7632e-02,  5.6445e-01,\n",
      "          6.5937e-01,  6.3253e-01,  1.1995e-02,  4.6673e-01,  4.2815e-01,\n",
      "          1.0256e+00, -4.5978e-01, -6.4501e-01,  2.1953e-01,  8.7451e-01,\n",
      "         -2.2185e-01,  4.4250e-01, -5.6321e-01, -1.0597e+00,  9.5971e-01,\n",
      "          9.1805e-01, -9.9491e-01, -5.3319e-02,  3.7871e-01,  5.5352e-01,\n",
      "          4.8097e-01, -4.0794e-01,  8.3272e-01,  6.2078e-01,  4.6955e-01,\n",
      "         -1.9214e-02,  1.6345e-01,  8.7310e-01, -7.7823e-01, -9.1429e-01,\n",
      "         -5.7500e-01,  9.9119e-01, -8.0620e-01, -6.2696e-01,  5.5386e-01,\n",
      "          1.0722e+00,  3.5581e-01,  9.6292e-01, -5.5097e-01, -8.7096e-01,\n",
      "          6.1759e-01, -3.5405e-01, -8.2347e-01, -7.0812e-02,  4.7410e-01,\n",
      "          8.3334e-01,  1.5566e-01,  7.3222e-01,  4.2938e-01, -8.5763e-01,\n",
      "         -3.4811e-01, -6.3878e-01,  2.6478e-01,  5.2082e-01, -6.7249e-01,\n",
      "          7.6277e-01, -2.5452e-01,  8.8643e-01, -3.2858e-01,  8.7686e-01,\n",
      "         -1.0353e+00,  1.1961e+00,  7.2060e-01, -4.7106e-02, -6.1705e-01,\n",
      "          7.1937e-02, -4.4088e-01,  8.7893e-01,  4.7579e-01, -6.3750e-02,\n",
      "          4.1745e-04, -1.2531e-01, -3.6318e-02, -1.9498e-01, -1.7300e-01,\n",
      "          1.5177e-01,  8.1974e-01, -1.5349e-01, -8.4898e-02, -2.7224e-01,\n",
      "         -1.2628e-01,  5.9214e-01, -3.2973e-01, -7.1675e-01, -4.7708e-01,\n",
      "          6.0630e-01, -7.3340e-02, -2.2885e-01,  1.4787e-01, -4.7844e-01,\n",
      "         -7.0552e-02,  8.4171e-01,  1.1810e-01,  7.1038e-01, -5.6071e-01,\n",
      "         -1.1883e+00,  4.9915e-01,  5.3200e-01,  7.0059e-01,  3.2596e-01,\n",
      "         -1.7346e-01,  2.2354e-01, -6.9431e-01,  8.2994e-01, -6.9160e-01,\n",
      "         -8.6537e-01,  1.1041e-01, -8.5771e-01,  5.6252e-01,  8.9605e-01,\n",
      "          9.3286e-02,  1.2798e+00,  9.2328e-01, -4.5245e-01, -2.9492e-01,\n",
      "         -1.9106e-01, -8.7311e-01,  5.9118e-01, -1.0137e+00,  1.0474e+00,\n",
      "         -6.6448e-01, -4.5059e-02, -1.1646e-01,  1.5879e-01,  5.5322e-01,\n",
      "          9.6304e-01, -5.8064e-01,  9.2951e-01,  8.9633e-01,  7.7306e-01,\n",
      "         -1.2364e+00, -7.7732e-01,  6.2543e-01, -9.9043e-01, -4.6584e-01,\n",
      "         -2.1680e-01, -2.1542e-01, -8.2594e-01,  8.0709e-01,  2.7768e-01,\n",
      "         -6.8998e-01,  8.7200e-01, -8.7587e-01,  5.4424e-02,  2.3723e-01,\n",
      "         -5.2323e-01, -4.1738e-01, -1.1127e+00, -7.3420e-01, -5.8078e-01,\n",
      "          2.0117e-01,  6.5567e-01,  7.0191e-01,  1.0713e-01, -2.5997e-01,\n",
      "         -8.5032e-01,  9.4226e-01,  3.2910e-01, -5.5021e-01, -2.3840e-01,\n",
      "         -8.6572e-01, -5.8049e-01,  9.9353e-01, -7.2013e-01,  6.8288e-01,\n",
      "          3.3548e-01,  5.7794e-02, -7.5633e-02, -1.8422e-01, -6.0143e-01,\n",
      "         -1.9561e-01,  7.0182e-01, -7.7544e-01,  8.3032e-01, -5.6428e-01,\n",
      "          1.4493e-01,  3.8002e-01,  1.0542e+00, -1.0143e+00,  7.6858e-01,\n",
      "         -8.7900e-01, -3.1049e-01,  1.0885e+00,  7.7368e-01, -4.2796e-01,\n",
      "         -6.1598e-01,  7.5501e-01, -6.6424e-01,  1.0424e+00,  5.2648e-01,\n",
      "         -7.4807e-03,  3.4623e-01, -4.3682e-01,  7.0405e-01,  1.5787e-01,\n",
      "         -1.0449e+00,  1.5392e-01, -7.1025e-01, -5.9252e-02, -5.3177e-01,\n",
      "          1.0049e-01, -8.8639e-01,  6.0897e-01,  7.5158e-01, -1.7696e-01,\n",
      "          9.0729e-01,  9.3477e-02, -1.1596e-01, -3.3181e-02,  1.2140e-01,\n",
      "         -8.3151e-01, -5.6254e-01,  7.3787e-01, -9.7688e-01,  6.0306e-01,\n",
      "          2.7673e-01, -5.3841e-01, -2.0254e-01, -9.3218e-01,  8.6538e-01,\n",
      "         -7.2982e-01,  2.7226e-01,  1.0907e+00,  8.3666e-01, -6.7631e-01,\n",
      "         -5.8009e-02, -5.7125e-01, -4.0651e-01,  4.1202e-01,  7.4831e-01,\n",
      "         -3.5904e-01, -1.7781e-01, -7.4020e-01, -9.8273e-02, -2.2022e-01,\n",
      "          9.1429e-01,  8.6889e-01,  3.0225e-01,  9.4280e-01, -1.7970e-01,\n",
      "         -5.2966e-01, -1.6670e-01,  8.2894e-01,  1.6536e-01,  1.2712e+00,\n",
      "          2.1477e-01, -5.7288e-01, -8.5059e-01,  8.1266e-01,  2.1116e-01,\n",
      "          7.1061e-04, -9.2820e-01,  7.4721e-01,  5.6548e-01, -6.9637e-01,\n",
      "          8.7320e-02, -4.4667e-01, -7.3367e-01,  6.3807e-01,  6.3673e-01,\n",
      "          5.3751e-01,  8.0793e-01,  5.2650e-01, -3.2680e-01,  5.6749e-01,\n",
      "         -6.6769e-01, -6.6633e-01, -8.1587e-01,  2.2813e-01, -7.0271e-02,\n",
      "         -2.2522e-01,  4.8540e-01,  6.9706e-01,  1.0870e+00, -5.3912e-01,\n",
      "         -1.0696e-01,  7.2789e-01,  2.6889e-01, -4.0398e-01, -8.7069e-02,\n",
      "          9.0413e-01,  5.7480e-01]], device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vae_model = vae_model.cpu()\n",
    "ohe_history = vae_model.decode(z_history.cpu())"
   ],
   "metadata": {
    "id": "3Wtt6T6hYHa-"
   },
   "execution_count": 164,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generated_smiles = [\n",
    "    decode_smiles_from_one_hot(ohe.detach().cpu().numpy(), charset)\n",
    "    for ohe in ohe_history\n",
    "]"
   ],
   "metadata": {
    "id": "vfnel8dzYaDM"
   },
   "execution_count": 165,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "init_smiles[0], generated_smiles"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezbe9olbYc9W",
    "outputId": "f5d8fbe5-8d6e-496e-abd1-9928c9a71873"
   },
   "execution_count": 166,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('CC(C)(C)c1ccc2ccc(CC(=O)Nc3ccccc3F)ccc1',\n",
       " ['CC(C)(C)c1ncc2ccc(CC(=O)NNc3cccc3F)c21',\n",
       "  'CC(C)(C)n1nnc2ncc(CC(=O)NNc3cccc3F)c2',\n",
       "  'NC(C)(CCn1nnc2ncc1CC(=O)NNc33ccc3F)s1',\n",
       "  'NCCC1[n@H]c2nnnn11CCC=O)[NH]]CC33nN33',\n",
       "  'O=C1[[)[nH]][H]nc1CC1=O[NHH]]2NN=NN3',\n",
       "  'O=CCC1[O=][[[=H]==CCC===[NNHHNN=N[NHHNN',\n",
       "  'O=CCC1[O[=[[[[HH]11CCCC==[[NHHHH[[[NNHHNNN',\n",
       "  'O=CC[[[][][[[[[[[[[H111CCCCCC[NNHH][NNHHHHHHNN',\n",
       "  'O=CC[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[',\n",
       "  'O=OO[H[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[',\n",
       "  ''])"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ]
  }
 ]
}