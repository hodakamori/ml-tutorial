{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import deepchem as dc\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from typing import List, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smiles_data(smiles_file_path: str):\n",
    "    lines = [\n",
    "        \"CCO\",\n",
    "        \"C[C@H](N)C(=O)O\",\n",
    "        \"Nc1ccc(cc1)C#N\",\n",
    "        \"CC(C)C(=O)NC\",\n",
    "        \"CC(C)Cc1ccccc1\",\n",
    "        \"CCOCC\",\n",
    "        \"CC(=O)Nc1ccccn1\",\n",
    "        \"CCc1ccc(cc1)Br\",\n",
    "        \"Cc1ccc(cc1)O\",\n",
    "        \"CN(C)C=O\",\n",
    "    ]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolGraphDataset(Dataset):\n",
    "    def __init__(self, smiles_list, transform=None):\n",
    "        super().__init__()\n",
    "        self.smiles_list = smiles_list\n",
    "        self.featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smi = self.smiles_list[idx]\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        mol = AllChem.AddHs(mol)\n",
    "        dgraph = self.featurizer.featurize([mol])[0]\n",
    "        pyg_data = self._dc_to_pyg(dgraph)\n",
    "        return pyg_data\n",
    "\n",
    "    def _dc_to_pyg(self, dgraph):\n",
    "        node_feats = torch.tensor(dgraph.node_features, dtype=torch.float)\n",
    "        edge_index = torch.tensor(dgraph.edge_index, dtype=torch.long)\n",
    "        edge_feats = torch.tensor(dgraph.edge_features, dtype=torch.float)\n",
    "\n",
    "        data = Data(x=node_feats, edge_index=edge_index, edge_attr=edge_feats)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_drop_edge(pyg_data: Data, drop_prob: float = 0.1):\n",
    "    edge_index = pyg_data.edge_index\n",
    "    edge_attr = pyg_data.edge_attr\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    mask = torch.rand(num_edges) > drop_prob\n",
    "    edge_index_new = edge_index[:, mask]\n",
    "    edge_attr_new = edge_attr[mask]\n",
    "\n",
    "    aug_data = Data(\n",
    "        x=pyg_data.x.clone(), edge_index=edge_index_new, edge_attr=edge_attr_new\n",
    "    )\n",
    "    return aug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask_node(pyg_data: Data, mask_prob: float = 0.1):\n",
    "    data = Data(\n",
    "        x=pyg_data.x.clone(),\n",
    "        edge_index=pyg_data.edge_index.clone(),\n",
    "        edge_attr=pyg_data.edge_attr.clone(),\n",
    "    )\n",
    "    node_mask = torch.rand(data.x.size(0)) < mask_prob\n",
    "    data.x[node_mask] = 0.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(\n",
    "    pyg_data: Data,\n",
    "    mode: List[Literal[\"drop_edge\", \"mask_node\"]],\n",
    "    edge_drop_prob: float = 0.1,\n",
    "    node_mask_prob: float = 0.1,\n",
    "):\n",
    "    data = pyg_data\n",
    "    if mode in [\"drop_edge\"]:\n",
    "        data = random_drop_edge(data, drop_prob=edge_drop_prob)\n",
    "    if mode in [\"mask_node\"]:\n",
    "        data = random_mask_node(data, mask_prob=node_mask_prob)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(\n",
    "    augment_mode: List[Literal[\"drop_edge\", \"mask_node\"]] = [\"drop_edge\", \"mask_node\"],\n",
    "    edge_drop_prob=0.1,\n",
    "    node_mask_prob=0.1,\n",
    "):\n",
    "    def collate_fn(batch):\n",
    "        aug1_list = []\n",
    "        aug2_list = []\n",
    "        for pyg_data in batch:\n",
    "            aug1 = augmentation(\n",
    "                pyg_data,\n",
    "                augment_mode,\n",
    "                edge_drop_prob=edge_drop_prob,\n",
    "                node_mask_prob=node_mask_prob,\n",
    "            )\n",
    "            aug2 = augmentation(\n",
    "                pyg_data,\n",
    "                augment_mode,\n",
    "                edge_drop_prob=edge_drop_prob,\n",
    "                node_mask_prob=node_mask_prob,\n",
    "            )\n",
    "            aug1_list.append(aug1)\n",
    "            aug2_list.append(aug2)\n",
    "        return aug1_list, aug2_list\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_node_features=20, num_edge_features=11, hidden_dim=64, out_dim=64\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.proj_head = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h_pool = global_mean_pool(h, batch_index)\n",
    "        z = self.proj_head(h_pool)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(z1, z2, temperature=0.1):\n",
    "    z1_norm = F.normalize(z1, p=2, dim=1)\n",
    "    z2_norm = F.normalize(z2, p=2, dim=1)\n",
    "    sim_matrix = torch.matmul(z1_norm, z2_norm.t())\n",
    "    sim_matrix = sim_matrix / temperature\n",
    "\n",
    "    # InfoNCE ロスの計算\n",
    "    logits_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)\n",
    "    sim_matrix_exp = torch.exp(sim_matrix - logits_max.detach())\n",
    "    pos = torch.diag(sim_matrix_exp)\n",
    "    denom = torch.sum(sim_matrix_exp, dim=1)\n",
    "    loss = -torch.log(pos / denom)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive(\n",
    "    smiles_file_path,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=1e-3,\n",
    "    augmentation_mode: List[Literal[\"drop_edge\", \"mask_node\"]] = [\n",
    "        \"drop_edge\",\n",
    "        \"mask_node\",\n",
    "    ],\n",
    "):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 1) SMILES データを読み込み\n",
    "    smiles_list = load_smiles_data(smiles_file_path)\n",
    "\n",
    "    # 2) Dataset & Dataloader 準備\n",
    "    dataset = MolGraphDataset(smiles_list)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=get_collate_fn(augment_mode=augmentation_mode),\n",
    "    )\n",
    "\n",
    "    # 3) GNNエンコーダ作成\n",
    "    encoder = GNNEncoder(num_node_features=30, num_edge_features=11)\n",
    "    encoder.to(device)  # GPU/CPUに転送\n",
    "\n",
    "    # 4) Optimizer\n",
    "    optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "\n",
    "    # 5) 学習ループ\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        encoder.train()\n",
    "        total_loss = 0.0\n",
    "        for aug1_list, aug2_list in dataloader:\n",
    "            batch_aug1 = Batch.from_data_list(aug1_list).to(device)\n",
    "            batch_aug2 = Batch.from_data_list(aug2_list).to(device)\n",
    "            # 順伝搬\n",
    "            z1 = encoder(\n",
    "                batch_aug1.x,\n",
    "                batch_aug1.edge_index,\n",
    "                batch_aug1.edge_attr,\n",
    "                batch_aug1.batch,\n",
    "            )\n",
    "            z2 = encoder(\n",
    "                batch_aug2.x,\n",
    "                batch_aug2.edge_index,\n",
    "                batch_aug2.edge_attr,\n",
    "                batch_aug2.batch,\n",
    "            )\n",
    "\n",
    "            # InfoNCE loss 計算\n",
    "            loss = info_nce_loss(z1, z2, temperature=0.1)\n",
    "\n",
    "            # 逆伝搬 & パラメータ更新\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch}/{epochs}] | Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/10] | Loss: 0.9307\n",
      "Epoch [2/10] | Loss: 0.7190\n",
      "Epoch [3/10] | Loss: 0.6168\n",
      "Epoch [4/10] | Loss: 0.6801\n",
      "Epoch [5/10] | Loss: 0.4665\n",
      "Epoch [6/10] | Loss: 0.3514\n",
      "Epoch [7/10] | Loss: 0.2592\n",
      "Epoch [8/10] | Loss: 0.3648\n",
      "Epoch [9/10] | Loss: 0.0859\n",
      "Epoch [10/10] | Loss: 0.3291\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_encoder = train_contrastive(\n",
    "    smiles_file_path=\"dummy_smiles.txt\",\n",
    "    epochs=10,\n",
    "    batch_size=4,\n",
    "    lr=1e-3,\n",
    "    augmentation_mode=[\"drop_edge\", \"mask_node\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
